{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAi9TTmX9lx0",
        "outputId": "fd100453-a06b-4133-d013-df2b5f12baea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTYtoQs09x53",
        "outputId": "c7409aa7-f86a-4651-c53a-aeceb810a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP/TaCL-main\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/NLP/TaCL-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36qOfpvgijSF"
      },
      "outputs": [],
      "source": [
        "!chmod +x download_benchmark_data.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W5Hcz5uiYAv",
        "outputId": "27b270ce-52e3-423a-ee19-7836518da698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=1Jc9Cvhbe8rhh0FeNUi26vLTcBfFZfOZw&export=download\n",
            "To: /content/drive/MyDrive/NLP/TaCL-main/benchmark_data.zip\n",
            "100% 30.7M/30.7M [00:00<00:00, 57.9MB/s]\n",
            "Archive:  benchmark_data.zip\n",
            "   creating: benchmark_data/\n",
            "  inflating: benchmark_data/.DS_Store  \n",
            "   creating: benchmark_data/NER/\n",
            "   creating: benchmark_data/CWS_data/\n",
            "  inflating: benchmark_data/NER/.DS_Store  \n",
            "   creating: benchmark_data/NER/ResumeNER/\n",
            "   creating: benchmark_data/NER/MSRANER/\n",
            "   creating: benchmark_data/NER/OntoNote4NER/\n",
            "   creating: benchmark_data/NER/WeiboNER/\n",
            "  inflating: benchmark_data/CWS_data/.DS_Store  \n",
            "   creating: benchmark_data/CWS_data/AS/\n",
            "   creating: benchmark_data/CWS_data/CITYU/\n",
            "   creating: benchmark_data/CWS_data/PKU/\n",
            "  inflating: benchmark_data/NER/ResumeNER/.DS_Store  \n",
            "  inflating: benchmark_data/NER/ResumeNER/ResumeNER.train.char.txt  \n",
            "  inflating: benchmark_data/NER/ResumeNER/ResumeNER.test.char.txt  \n",
            "  inflating: benchmark_data/NER/ResumeNER/ResumeNER.dev.char.txt  \n",
            "  inflating: benchmark_data/NER/ResumeNER/ResumeNER_NER_label.txt  \n",
            "  inflating: benchmark_data/NER/MSRANER/.DS_Store  \n",
            "  inflating: benchmark_data/NER/MSRANER/MSRA_NER_Label.txt  \n",
            "  inflating: benchmark_data/NER/MSRANER/MSRA.train.char.txt  \n",
            "  inflating: benchmark_data/NER/MSRANER/MSRA.dev.char.txt  \n",
            "  inflating: benchmark_data/NER/MSRANER/MSRA.test.char.txt  \n",
            "  inflating: benchmark_data/NER/OntoNote4NER/.DS_Store  \n",
            "  inflating: benchmark_data/NER/OntoNote4NER/OntoNote4NER_NER_Label.txt  \n",
            "  inflating: benchmark_data/NER/OntoNote4NER/OntoNote4NER.dev.char.txt  \n",
            "  inflating: benchmark_data/NER/OntoNote4NER/OntoNote4NER.test.char.txt  \n",
            "  inflating: benchmark_data/NER/OntoNote4NER/OntoNote4NER.train.char.txt  \n",
            "  inflating: benchmark_data/NER/WeiboNER/Weibo_NER_Label.txt  \n",
            "  inflating: benchmark_data/NER/WeiboNER/Weibo.train.all.char.txt  \n",
            "  inflating: benchmark_data/NER/WeiboNER/Weibo.dev.all.char.txt  \n",
            "  inflating: benchmark_data/NER/WeiboNER/Weibo.test.all.char.txt  \n",
            "  inflating: benchmark_data/CWS_data/AS/as_label.txt  \n",
            "  inflating: benchmark_data/CWS_data/AS/.DS_Store  \n",
            "  inflating: benchmark_data/CWS_data/AS/as_train.txt  \n",
            "  inflating: benchmark_data/CWS_data/AS/as_test.txt  \n",
            "  inflating: benchmark_data/CWS_data/CITYU/cityu_label.txt  \n",
            "  inflating: benchmark_data/CWS_data/CITYU/.DS_Store  \n",
            "  inflating: benchmark_data/CWS_data/CITYU/cityu_train.txt  \n",
            "  inflating: benchmark_data/CWS_data/CITYU/cityu_test.txt  \n",
            "  inflating: benchmark_data/CWS_data/PKU/.DS_Store  \n",
            "  inflating: benchmark_data/CWS_data/PKU/pku_test_processed.txt  \n",
            "  inflating: benchmark_data/CWS_data/PKU/pku_train_all_processed.txt  \n",
            "  inflating: benchmark_data/CWS_data/PKU/PKU_CWS_label.txt  \n",
            "  inflating: benchmark_data/CWS_data/PKU/pku_dev_processed.txt  \n",
            "rm: cannot remove '__MACOSX': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./download_benchmark_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuNM8Jv6lDEm",
        "outputId": "d7068707-ecb2-42c9-c6fa-dd6f6150cf66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?export=download&confirm=LAJS&id=1EQ0uqBH_6je2eqd5-tFZFqVrL1sUljaO\n",
            "To: /content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark/pretrained_ckpt.zip\n",
            "100% 2.66G/2.66G [00:28<00:00, 91.7MB/s]\n",
            "Archive:  pretrained_ckpt.zip\n",
            "replace pretrained_ckpt/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!./download_checkpoints.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3Q6ZbVt919c"
      },
      "outputs": [],
      "source": [
        "!chmod +x download_checkpoints.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiKJfhtRjAxF",
        "outputId": "0960679a-c2a7-45f0-d423-c5ca41f49f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'chinese_benchmark/'\n",
            "/content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark\n"
          ]
        }
      ],
      "source": [
        "cd chinese_benchmark/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLLkTabr-eeu",
        "outputId": "c3ad9853-3137-49ea-952c-f2a878c9912a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark/sh_folder/inference\n"
          ]
        }
      ],
      "source": [
        "cd ./sh_folder/inference/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw4A9rUh-j_y",
        "outputId": "2ca38cc8-e955-466d-9e40-1a3a69e2c0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmz3k1gIm05L",
        "outputId": "562950c0-cea6-4891-e389-fb60199a824d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TorchCRF\n",
            "  Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from TorchCRF) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TorchCRF) (1.22.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->TorchCRF) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->TorchCRF) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->TorchCRF) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->TorchCRF) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->TorchCRF) (1.3.0)\n",
            "Installing collected packages: TorchCRF\n",
            "Successfully installed TorchCRF-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install TorchCRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUxRvtV8_F4j"
      },
      "outputs": [],
      "source": [
        "!chmod +x ./inference_msra.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhPTFAJclpwL",
        "outputId": "606262b7-334e-45f1-f978-f6635b708c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34meval_folder\u001b[0m/        inference_msra.sh       inference_resume.sh\n",
            "inference_as.sh     inference_ontonotes.sh  inference_weibo.sh\n",
            "inference_cityu.sh  inference_pku.sh\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teNUA7Hc-9I6",
        "outputId": "473d7599-c4ef-4e38-f278-971d0756723a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available.\n",
            "Loading data...\n",
            "number of tags is 13\n",
            "training number is 37000, dev number is 9364, test_num is 4365\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Model Loaded.\n",
            "gold_num =  5558  pred_num =  5561  right_num =  5306\n",
            "0.9541449379607985 0.9546599496221663 0.9544023743142369\n",
            "------------------------------------------------------------\n",
            "Test Evaluation Results are Precision: 0.954, Recall: 0.955, F1: 0.954\n"
          ]
        }
      ],
      "source": [
        "!./inference_msra.sh "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agPIaQMfobHJ",
        "outputId": "edc08143-559e-4931-fc5f-234b476d1ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available.\n",
            "Loading data...\n",
            "number of tags is 17\n",
            "training number is 15724, dev number is 4301, test_num is 4346\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Model Loaded.\n",
            "gold_num =  7601  pred_num =  7703  right_num =  6307\n",
            "0.8187719070492017 0.829759242204973 0.8242289597490853\n",
            "------------------------------------------------------------\n",
            "Test Evaluation Results are Precision: 0.819, Recall: 0.83, F1: 0.824\n"
          ]
        }
      ],
      "source": [
        "!chmod +x ./inference_ontonotes.sh\n",
        "!./inference_ontonotes.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SawSouGtpIgG",
        "outputId": "bed03d92-7fe4-4e61-e062-52a11d9fb67b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available.\n",
            "Loading data...\n",
            "number of tags is 28\n",
            "training number is 3821, dev number is 463, test_num is 477\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Model Loaded.\n",
            "gold_num =  1620  pred_num =  1619  right_num =  1562\n",
            "0.964793082149475 0.9641975308641976 0.964495214572399\n",
            "------------------------------------------------------------\n",
            "Test Evaluation Results are Precision: 0.965, Recall: 0.964, F1: 0.964\n"
          ]
        }
      ],
      "source": [
        "!chmod +x ./inference_resume.sh\n",
        "!./inference_resume.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98vJzFGYq1R4",
        "outputId": "a8fa6935-5399-4b24-a5fa-2e01f4ae4d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available.\n",
            "Loading data...\n",
            "number of tags is 28\n",
            "training number is 1350, dev number is 270, test_num is 270\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Model Loaded.\n",
            "gold_num =  410  pred_num =  424  right_num =  290\n",
            "0.6839622641509434 0.7073170731707317 0.6954436450839329\n",
            "------------------------------------------------------------\n",
            "Test Evaluation Results are Precision: 0.684, Recall: 0.707, F1: 0.695\n"
          ]
        }
      ],
      "source": [
        "!chmod +x ./inference_weibo.sh\n",
        "!./inference_weibo.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQIsoIRssZUy",
        "outputId": "da7028fa-591b-4aaa-ada9-98e69faa7062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda is available.\n",
            "Loading data...\n",
            "number of tags is 5\n",
            "training number is 19056, dev number is 1906, test_num is 1945\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Model Loaded.\n",
            "gold_num =  81502  pred_num =  81012  right_num =  78613\n",
            "0.970387103145213 0.9645530171038748 0.9674612648756415\n",
            "------------------------------------------------------------\n",
            "Test Evaluation Results are Precision: 0.97, Recall: 0.965, F1: 0.967\n"
          ]
        }
      ],
      "source": [
        "!chmod +x ./inference_pku.sh\n",
        "!./inference_pku.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcV5CcXRs0Sy",
        "outputId": "20582902-04c9-4b23-933e-b2adfed731f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCLu2yyrzPQF",
        "outputId": "ef9bf40b-b5bf-4990-ce0c-1af49486c41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0AFefw4CzgRa",
        "outputId": "13aa5262-1184-499e-847f-83a34050b621"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYci4RZEzJ9k",
        "outputId": "6661c8e4-d1e7-434d-e104-2a27c29e12ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP/TaCL-main/chinese_benchmark/sh_folder/train\n"
          ]
        }
      ],
      "source": [
        "#cd sh_folder/train\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFz_26EQz5le",
        "outputId": "fa23ba6b-35e4-4cf6-cfa5-2b92b2fef7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "Evaluatiing model bert-base-chinese\n",
            "######\n",
            "start run 0\n",
            "Loading data...\n",
            "number of tags is 13\n",
            "training number is 37000, dev number is 9364, test_num is 4365\n",
            "Maximum train sequence length: 130, dev sequence length: 130, test sequence length: 130\n",
            "Data loaded.\n",
            "Loading model...\n",
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model loaded.\n",
            "------------------------------------------------------------------\n",
            "Start epoch 0 training...\n",
            "/ |#                                                | 1851 Elapsed Time: 0:00:00/usr/local/lib/python3.10/dist-packages/TorchCRF/__init__.py:173: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)\n",
            "  score = torch.where(mask_t, score_t, score)\n",
            "- |          #                                       | 181 Elapsed Time: 0:59:31"
          ]
        }
      ],
      "source": [
        "!chmod +x ./msra.sh\n",
        "!./msra.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to premium GPUs. You can upgrade your notebook's GPU settings in `Runtime > Change runtime type` in the menu to enable Premium accelerator. Subject to availability, selecting a premium GPU may grant you access to a V100 or A100 Nvidia GPU.\n",
        "\n",
        "The free of charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to `Runtime > Change runtime type` in the menu to enable a GPU accelerator, and then re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the `Runtime > Change runtime type` menu, and then set the hardware accelerator dropdown to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available.\n",
        "\n",
        "\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via `Runtime > Change runtime type` in the menu. Then select High-RAM in the Runtime shape dropdown. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via Pay As You Go. Anyone can purchase compute units via [Pay As You Go](https://colab.research.google.com/signup); no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro, Pro+, or Pay As You Go, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}