{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_JyG8iAa0Az",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Transalte and Paraphrase\n",
        "# Optional code to translate and paraphrase used for my testing and creating augmented dataset\n",
        "# import pandas as pd\n",
        " \n",
        "# # Data.tsv is stored locally in the\n",
        "# # same directory as of this python file\n",
        "# final_df = pd.read_csv('/content/final_data.tsv',sep='\\t')\n",
        "# # pd.set_option('max_colwidth', None)\n",
        "# # final_df.head(100)\n",
        "# final_df['label'] = final_df['label'].str.strip().str.lower()\n",
        "# # final=final_df.label.unique()\n",
        "# # final_df.head(100)\n",
        "# # print(final)\n",
        "# # print(len(final))\n",
        "# # create a mapping between old and new names\n",
        "# label_name_map = {\n",
        "#     \"economic\": \"Economic\",\n",
        "#     \"policy prescription and evaluation\": \"Policy Prescription and Evaluation\",\n",
        "#     \"capacity and resources\": \"Capacity and Resources\",\n",
        "#     \"public opinion\": \"Public Sentiment\",\n",
        "#     \"cultural identity\": \"Cultural Identity\",\n",
        "#     \"fairness and equality\": \"Fairness and Equality\",\n",
        "#     \"legality, constitutionality, and jurisprudence\": \"Legality, Constitutionality, Jurisdiction\",\n",
        "#     \"political\": \"Political\",\n",
        "#     \"morality\": \"Morality\",\n",
        "#     \"health and safety\": \"Health and Safety\",\n",
        "#     \"quality of life\": \"Quality of Life\",\n",
        "#     \"security and defense\": \"Security and Defense\",\n",
        "#     \"other\": \"Other\",\n",
        "#     \"external regulation and reputation\": \"External Regulation and Reputation\",\n",
        "#     \"crime and punishment\": \"Crime and Punishment\"\n",
        "# }\n",
        "\n",
        "# # update the label column with new names\n",
        "# final_df[\"label\"] = final_df[\"label\"].replace(label_name_map)\n",
        "\n",
        "# # print the updated DataFrame\n",
        "# # print(final_df)\n",
        "\n",
        "# # final_df['label'] = final_df['label'].str.strip().str.lower()\n",
        "# # final=final_df.label.unique()\n",
        "# # final_df.head(100)\n",
        "\n",
        "# # print(final)\n",
        "# # Define the label-ID mapping\n",
        "# label_id_mapping = {\n",
        "#     \"None\" : \"0.0\",\n",
        "#     \"Economic\": \"1.0\",\n",
        "#     \"Capacity and Resources\": \"2.0\",\n",
        "#     \"Morality\": \"3.0\",\n",
        "#     \"Fairness and Equality\": \"4.0\",\n",
        "#     \"Legality, Constitutionality, Jurisdiction\": \"5.0\",\n",
        "#     \"Policy Prescription and Evaluation\": \"6.0\",\n",
        "#     \"Crime and Punishment\": \"7.0\",\n",
        "#     \"Security and Defense\": \"8.0\",\n",
        "#     \"Health and Safety\": \"9.0\",\n",
        "#     \"Quality of Life\": \"10.0\",\n",
        "#     \"Cultural Identity\": \"11.0\",\n",
        "#     \"Public Sentiment\": \"12.0\",\n",
        "#     \"Political\": \"13.0\",\n",
        "#     \"External Regulation and Reputation\": \"14.0\",\n",
        "#     \"Other\": \"15.0\"\n",
        "# }\n",
        "\n",
        "# # Map the label names to label IDs using the mapping dictionary\n",
        "# final_df['label_id'] = final_df['label'].map(label_id_mapping)\n",
        "\n",
        "# # Get the row count of the DataFrame\n",
        "# row_count = final_df.shape[0]\n",
        "\n",
        "# # Print the row count\n",
        "# print(\"The DataFrame has {} rows.\".format(row_count))\n",
        "\n",
        "# !pip install googletrans==4.0.0-rc1\n",
        "# # Import necessary libraries\n",
        "# from googletrans import Translator\n",
        "# import pandas as pd\n",
        "\n",
        "# # Create a translator object\n",
        "# translator = Translator()\n",
        "\n",
        "# # Define a function to translate text to English\n",
        "# def translate_to_english(text, lang):\n",
        "#     if lang == 'eng':\n",
        "#         return text\n",
        "#     else:\n",
        "#         translated = translator.translate(text, dest='en')\n",
        "#         return translated.text\n",
        "\n",
        "# # Load the final_df dataframe with text and language columns\n",
        "# # final_df = pd.read_csv('final_df.csv')\n",
        "# # Apply the translation function to each row in the dataframe\n",
        "# final_df['english_text'] = final_df.apply(lambda row: translate_to_english(row['text'], row['language']), axis=1)\n",
        "\n",
        "# # Display the updated dataframe\n",
        "# # print(final_df)\n",
        "\n",
        "# # Create a new DataFrame with the English text as the text column and other columns the same\n",
        "# new_df = pd.DataFrame({\n",
        "#     'text': final_df['english_text'],\n",
        "#     'language': 'eng',\n",
        "#     'label': final_df['label'],\n",
        "#     'source': final_df['source'],\n",
        "#     'annotator': final_df['annotator'],\n",
        "#     'label_id': final_df['label_id']\n",
        "# })\n",
        "# # Define a list of languages to translate to\n",
        "# languages =['zh-CN', 'hi', 'te', 'ne', 'bn', 'el', 'de', 'sw', 'tr', 'it']\n",
        "\n",
        "# # Define a function to translate text to a given language\n",
        "# def translate_text(text, dest_lang):\n",
        "#     translated = translator.translate(text, dest=dest_lang)\n",
        "#     return translated.text\n",
        "\n",
        "# # Loop through each language and add the translated rows to the DataFrame\n",
        "# for lang in languages:\n",
        "#     # Apply the translation function to each row in the dataframe\n",
        "#     new_rows = final_df.apply(lambda row: translate_text(row['english_text'], lang), axis=1)\n",
        "    \n",
        "#     # Create a new DataFrame with the translated rows\n",
        "#     translated_df = pd.DataFrame({\n",
        "#         'text': new_rows,\n",
        "#         'language': lang,\n",
        "#         'label': final_df['label'],\n",
        "#         'source': final_df['source'],\n",
        "#         'annotator': final_df['annotator'],\n",
        "#         'label_id': final_df['label_id']\n",
        "#     })\n",
        "    \n",
        "#     # Append the translated rows to the original DataFrame\n",
        "#     new_df = new_df.append(translated_df, ignore_index=True)\n",
        "\n",
        "# !pip install transformers\n",
        "\n",
        "# !pip install sentencepiece\n",
        "\n",
        "# # Import necessary libraries\n",
        "# import torch\n",
        "# from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast\n",
        "\n",
        "# # Load Pegasus model and tokenizer\n",
        "# model_name = 'google/pegasus-xsum'\n",
        "# tokenizer = PegasusTokenizerFast.from_pretrained(model_name)\n",
        "# model = PegasusForConditionalGeneration.from_pretrained(model_name).cuda()\n",
        "\n",
        "# # Define a function to paraphrase text\n",
        "# def paraphrase_text(text):\n",
        "#     input_ids = tokenizer.encode(text, return_tensors='pt').cuda()\n",
        "#     output = model.generate(input_ids, max_length=256, num_beams=10, early_stopping=True)\n",
        "#     paraphrased_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "#     return paraphrased_text\n",
        "\n",
        "# # Apply the paraphrasing function to each row in the dataframe\n",
        "# # new_df['paraphrased_text'] = new_df['text'].apply(paraphrase_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9sg6ZGBk3R1j"
      },
      "outputs": [],
      "source": [
        "# Load Augmented Datset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#change data path as necessary\n",
        "aug_df = pd.read_csv('/content/french_hw2.csv',sep=',')\n",
        "aug_df = aug_df.dropna()\n",
        "# fi_df = pd.read_csv('/content/final_data.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2BnCZXnFut0P",
        "outputId": "bcd3853f-9202-4b20-8ff5-25eaaa459bc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence  label_ID\n",
              "0    Les mariages SAM-SEX deviennent courants dans ...        15\n",
              "1    L'acceptation par le gouvernement du mariage g...        11\n",
              "2    Des règles adéquates de santé et de sécurité d...         9\n",
              "3    La stabilité financière et l'accès aux ressour...        10\n",
              "4    Les dirigeants politiques ont discuté des avan...        13\n",
              "..                                                 ...       ...\n",
              "295  L'arrivée des immigrants dans un nouveau pays ...         7\n",
              "296  Les implications en matière de santé et de séc...         9\n",
              "297  L'autorité publique de diverses nations a pris...         7\n",
              "298  Le mariage égal-sexe fournit la même liberté e...        10\n",
              "299  La reconnaissance de l'égalité de mariage sexu...         7\n",
              "\n",
              "[300 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4733615d-d678-4ddb-bb47-d5ed58474c08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les mariages SAM-SEX deviennent courants dans ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L'acceptation par le gouvernement du mariage g...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Des règles adéquates de santé et de sécurité d...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La stabilité financière et l'accès aux ressour...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Les dirigeants politiques ont discuté des avan...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>L'arrivée des immigrants dans un nouveau pays ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>Les implications en matière de santé et de séc...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>L'autorité publique de diverses nations a pris...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>Le mariage égal-sexe fournit la même liberté e...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>La reconnaissance de l'égalité de mariage sexu...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4733615d-d678-4ddb-bb47-d5ed58474c08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4733615d-d678-4ddb-bb47-d5ed58474c08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4733615d-d678-4ddb-bb47-d5ed58474c08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23zfO_ALKeB"
      },
      "source": [
        "# Part 2: Model Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N25dvF4jvYoy"
      },
      "source": [
        "Now we'll move onto fine-tuning  pretrained language models specifically on your dataset. This part of the homework is meant to be an introduction to the HuggingFace library, and it contains code that will potentially be useful for your final projects. Since we're dealing with large models, the first step is to change to a GPU runtime.\n",
        "\n",
        "## Adding a hardware accelerator\n",
        "\n",
        "Please go to the menu and add a GPU as follows:\n",
        "\n",
        "`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n",
        "\n",
        "Run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edOh9ooiIW1B",
        "outputId": "8c6640fc-c606-458b-f382-152caae48d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvH7xx9LnMC"
      },
      "source": [
        "## Installing Hugging Face's Transformers library\n",
        "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n",
        "\n",
        "Run the following cell to install Hugging Face's Transformers library and download a sample data file called seed.tsv that contains 250 sentences in English, annotated with their frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqS2e5fxpqa"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XIL7wPovVX"
      },
      "source": [
        "The cell below imports some helper functions we wrote to demonstrate the task on the sample seed dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Taseb33Sovg0"
      },
      "outputs": [],
      "source": [
        "from helpers import tokenize_and_format, flat_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKc0xYh-MAbc"
      },
      "source": [
        "# Part 1: Data Prep and Model Specifications\n",
        "\n",
        "Upload your data using the file explorer to the left. We have provided a function below to tokenize and format your data as BERT requires. Make sure that your tsv file, titled final_data.tsv, has one column \"sentence\" and another column \"labels_ID\" containing integers/float.\n",
        "\n",
        "If you run the cell below without modifications, it will run on the seed.tsv example data we have provided. It imports some helper functions we wrote to demonstrate the task on the sample dataset. You should first run all of the following cells with seed.tsv just to see how everything works. Then, once you understand the whole preprocessing / fine-tuning process, change the tsv in the below cell to your final_data.tsv file, add any extra preprocessing code you wish, and then run the cells again on your own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "df346893a0f04769b094faa661ac509f",
            "796ce3de49a849eb92e269b99fd627ad",
            "8436dc34e32b48e49240427cb62215aa",
            "011dcb6824bc4e1c8d0b44a33c0f5a09",
            "4bbb9499456442798dfc83f8b7a14160",
            "85192cfd194c4a0f8239a79aaac0151a",
            "6fc7e3e588c24400b3acabbfd269b95f",
            "365e77a0f26a4853ba068550d6305142",
            "eed7a3f5f59d4b219b468b6573f3cc66",
            "07f4ec0b9a5a45a99756be2dc8de53a9",
            "7cf86b529c6f4798af8895132b28f9a4",
            "6386d565c2244b41a13b732d1e3ac744",
            "44fe7d140fbd4cda9113ba121088d583",
            "60e39b7bffa54fbc990ac606030f5e91",
            "ff91dfe9c2134a469570320d9cefb51a",
            "cf50d97c409d45798650790c5b2ad9ab",
            "e514881e37534da585e0f3a86936cd9f",
            "ca241f0c99e94627b12c0a4e4b072887",
            "8d2e3cdb42dd439b9133a542acc9cfda",
            "0777bd360f5b490ea4897643c1ccaef0",
            "2df8998d8eaf4265bd064199f0029056",
            "b530233a90494d47bd2c615f2fcc1c3c",
            "f51bb3e8cebf4a9f83174c7736344670",
            "4a562e5791b94cb39cf2f87967e7274e",
            "4468e5b80fd44321a0ceb1c37f73d052",
            "7bf4761c4a1d442d927b677f1347257f",
            "c29958326c5e499cb23437cb2612d8a9",
            "869413a2c46b40b692fda2c13ede61f4",
            "23ab09409aba4c34a35049b026d7aa80",
            "c2b24b917d2849638690bce24c232ada",
            "60d62cfc078d4187b2cb6416c8bffa9e",
            "e666d765cb604a45aaf01cecdd771772",
            "b7f0cb6b6f684ac0b95ae6234f5d30d3"
          ]
        },
        "id": "YGhkeLQlNNr8",
        "outputId": "00211897-e406-4b82-bc7d-3fcb3eac5177"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df346893a0f04769b094faa661ac509f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6386d565c2244b41a13b732d1e3ac744"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f51bb3e8cebf4a9f83174c7736344670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  L'immigration est un élément important de l'histoire humaine, et il peut avoir un impact significatif sur l'identité culturelle d'une personne.\n",
            "Token IDs: tensor([  101,   154,   112, 38451, 10182, 10119, 16644, 12652, 10102,   154,\n",
            "          112, 13119, 53310,   117, 10137, 10145, 12835, 13810, 10119, 17796,\n",
            "        17929, 21369, 10344,   154,   112, 59321, 76385,   146,   112, 10249,\n",
            "        28161,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "from helpers import tokenize_and_format, flat_accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "aug_df[\"label_ID\"] = aug_df[\"label_ID\"].astype(float)\n",
        "# fi_df[\"label_id\"] = fi_df[\"label_id\"].astype(float)\n",
        "# df = fi_df\n",
        "# df = pd.read_csv('seed.tsv')\n",
        "df = aug_df\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "texts = df.sentence.values\n",
        "labels = df.label_ID.values\n",
        "\n",
        "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "input_ids, attention_masks = tokenize_and_format(texts)\n",
        "\n",
        "label_list = []\n",
        "for l in labels:\n",
        "  label_array = np.zeros(len(set(labels)))\n",
        "  label_array[int(l)-1] = 1\n",
        "  label_list.append(label_array)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(np.array(label_list))\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3D-CzQEUXYz"
      },
      "source": [
        "## Create train/test/validation splits\n",
        "\n",
        "Here we split your dataset into 3 parts: a training set, a validation set, and a testing set. Each item in your dataset will be a 3-tuple containing an input_id tensor, an attention_mask tensor, and a label tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kGgeZ3M0UWs0"
      },
      "outputs": [],
      "source": [
        "\n",
        "total = len(df)\n",
        "\n",
        "num_train = int(total * .8)\n",
        "num_val = int(total * .1)\n",
        "num_test = total - num_train - num_val\n",
        "\n",
        "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
        "\n",
        "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n",
        "val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n",
        "test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n",
        "\n",
        "train_text = [texts[i] for i in range(num_train)]\n",
        "val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n",
        "test_text = [texts[i] for i in range(num_val + num_train, total)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCr006iTkqwM"
      },
      "source": [
        "Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lPo640_ZlEPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d525e138-fe5b-46db-ad7c-7a071527a075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sandeepvarma99/tacl-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"sandeepvarma99/tacl-french\", # model\n",
        "    num_labels = 15, # The number of output labels.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "# model.dropout = nn.Dropout(p=0.1)\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n",
        "# print(model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3lLdoW_le3M"
      },
      "source": [
        "# ACTION REQUIRED #\n",
        "\n",
        "Define your fine-tuning hyperparameters in the cell below (we have randomly picked some values to start with). We want you to experiment with different configurations to find the one that works best (i.e., highest accuracy) on your validation set. Feel free to also change pretrained models to others available in the HuggingFace library (you'll have to modify the cell above to do this). You might find papers on BERT fine-tuning stability (e.g., [Mosbach et al., ICLR 2021](https://openreview.net/pdf?id=nzpLWnVAyah)) to be of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Dd2JdC6IletV"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "optimizer = AdamW(model.parameters(),lr=5e-05) #with default values of learning rate and epsilon value\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd4fwn_el1ge"
      },
      "source": [
        "# Fine-tune your model\n",
        "Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O_Mzr-kd5RaY"
      },
      "outputs": [],
      "source": [
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = (logits).detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = np.argmax(label_ids, axis=1).flatten()\n",
        "\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"Num of correct predictions =\", total_correct)\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "    return avg_val_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTf_ipbjWNoV",
        "outputId": "0a235119-917a-4b26-aff0-c159a7bf610c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.2585902260027878\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.2457738999067159\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.2306817524080139\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.21507233057442743\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.2029948530786593\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.19144185050487675\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.1806408211808755\n",
            "Num of correct predictions = 21\n",
            "Validation accuracy: 0.7\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.17144745302438322\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.161642719121624\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.1520861190976575\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.14589875539111544\n",
            "Num of correct predictions = 21\n",
            "Validation accuracy: 0.7\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.13784356516747115\n",
            "Num of correct predictions = 23\n",
            "Validation accuracy: 0.7666666666666667\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.13216661502907906\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.12616310580956958\n",
            "Num of correct predictions = 21\n",
            "Validation accuracy: 0.7\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.12074651804852893\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.11540702993532047\n",
            "Num of correct predictions = 23\n",
            "Validation accuracy: 0.7666666666666667\n",
            "\n",
            "======== Epoch 17 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.11039092359650467\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 18 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.10535213367903554\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 19 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.10194006666780397\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "======== Epoch 20 / 20 ========\n",
            "Training...\n",
            "Total loss: 0.09730345804370397\n",
            "Num of correct predictions = 22\n",
            "Validation accuracy: 0.7333333333333333\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# training loop\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    num_batches = int(len(train_set)/batch_size) + 1\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      end_index = min(batch_size * (i+1), len(train_set))\n",
        "\n",
        "      batch = train_set[i*batch_size:end_index]\n",
        "\n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device) \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      # Clear the previously calculated gradient\n",
        "      model.zero_grad()     \n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      optimizer.step()\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set. Implement this function in the cell above.\n",
        "    print(f\"Total loss: {total_train_loss}\")\n",
        "    val_acc = get_validation_performance(val_set)\n",
        "    print(f\"Validation accuracy: {val_acc}\")\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9DpRJE5mHkO"
      },
      "source": [
        "# Evaluate your model on the test set\n",
        "After you're satisfied with your hyperparameters (i.e., you're unable to achieve higher validation accuracy by modifying them further), it's time to evaluate your model on the test set! Run the below cell to compute test set accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msvZ78ii3cZZ",
        "outputId": "8404e593-f1c4-42ae-b73d-ad7bc03a1730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of correct predictions = 23\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "get_validation_performance(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBbdMwt79fIs"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X72mumhI9WdR",
        "outputId": "278c528c-1f05-4e45-9f41-458047e26a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of correct predictions = 23\n",
            "Test accuracy: 0.7666666666666667\n",
            "Number of wrong examples: 7\n",
            "wrong examples:\n",
            "\n",
            "Example 1:\n",
            "Text: Divers pays ont constaté une augmentation de la migration illégale qui a mis un poids excessif sur leurs propriétés.\n",
            "Predicted label: 15\n",
            "True label: 7\n",
            "\n",
            "Example 2:\n",
            "Text: Il est important de considérer les implications morales des politiques d'immigration, ainsi que la façon dont elles peuvent affecter les personnes touchées.\n",
            "Predicted label: 13\n",
            "True label: 3\n",
            "\n",
            "Example 3:\n",
            "Text: Atteindre une meilleure éducation, des soins de santé et des possibilités d'emploi peut augmenter considérablement la qualité de vie pour les immigrants.\n",
            "Predicted label: 9\n",
            "True label: 10\n",
            "\n",
            "Example 4:\n",
            "Text: Les conséquences légales et constitutionnelles du mariage gay ont reçu une attention considérable ces dernières années.\n",
            "Predicted label: 15\n",
            "True label: 5\n",
            "\n",
            "Example 5:\n",
            "Text: Nous devons nous tenir contre toute tentative de créer un système de justice à deuxtières, où les immigrants sont traités de manière inégale.\n",
            "Predicted label: 5\n",
            "True label: 4\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_acc = get_validation_performance(test_set)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "total_test_loss = 0\n",
        "total_correct = 0\n",
        "wrong_examples = []\n",
        "\n",
        "num_batches = int(len(test_set)/batch_size) + 1\n",
        "\n",
        "for i in range(num_batches):\n",
        "    end_index = min(batch_size * (i+1), len(test_set))\n",
        "    batch = test_set[i*batch_size:end_index]\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        continue\n",
        "\n",
        "    input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "    input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "    label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "    # Move tensors to the GPU\n",
        "    b_input_ids = input_id_tensors.to(device)\n",
        "    b_input_mask = input_mask_tensors.to(device)\n",
        "    b_labels = label_tensors.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Accumulate the test loss\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = (logits).detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = np.argmax(label_ids, axis=1).flatten()\n",
        "\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "\n",
        "        # Find examples that the model gets wrong\n",
        "        for j in range(len(batch)):\n",
        "            if pred_flat[j] != labels_flat[j]:\n",
        "                text = test_text[i*batch_size+j]\n",
        "                predicted_label = pred_flat[j] + 1\n",
        "                true_label = labels_flat[j] + 1\n",
        "                wrong_examples.append((text, predicted_label, true_label))\n",
        "\n",
        "# Print some of the examples that the model gets wrong\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "print(\"Number of wrong examples:\", len(wrong_examples))\n",
        "print(\"wrong examples:\")\n",
        "for i, (text, predicted_label, true_label) in enumerate(wrong_examples[:5]):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Predicted label:\", predicted_label)\n",
        "    print(\"True label:\", true_label)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SgNZTjrhcHa0"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df346893a0f04769b094faa661ac509f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_796ce3de49a849eb92e269b99fd627ad",
              "IPY_MODEL_8436dc34e32b48e49240427cb62215aa",
              "IPY_MODEL_011dcb6824bc4e1c8d0b44a33c0f5a09"
            ],
            "layout": "IPY_MODEL_4bbb9499456442798dfc83f8b7a14160"
          }
        },
        "796ce3de49a849eb92e269b99fd627ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85192cfd194c4a0f8239a79aaac0151a",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc7e3e588c24400b3acabbfd269b95f",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "8436dc34e32b48e49240427cb62215aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365e77a0f26a4853ba068550d6305142",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eed7a3f5f59d4b219b468b6573f3cc66",
            "value": 871891
          }
        },
        "011dcb6824bc4e1c8d0b44a33c0f5a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f4ec0b9a5a45a99756be2dc8de53a9",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf86b529c6f4798af8895132b28f9a4",
            "value": " 872k/872k [00:00&lt;00:00, 5.66MB/s]"
          }
        },
        "4bbb9499456442798dfc83f8b7a14160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85192cfd194c4a0f8239a79aaac0151a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc7e3e588c24400b3acabbfd269b95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "365e77a0f26a4853ba068550d6305142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed7a3f5f59d4b219b468b6573f3cc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f4ec0b9a5a45a99756be2dc8de53a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf86b529c6f4798af8895132b28f9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6386d565c2244b41a13b732d1e3ac744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fe7d140fbd4cda9113ba121088d583",
              "IPY_MODEL_60e39b7bffa54fbc990ac606030f5e91",
              "IPY_MODEL_ff91dfe9c2134a469570320d9cefb51a"
            ],
            "layout": "IPY_MODEL_cf50d97c409d45798650790c5b2ad9ab"
          }
        },
        "44fe7d140fbd4cda9113ba121088d583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e514881e37534da585e0f3a86936cd9f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca241f0c99e94627b12c0a4e4b072887",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "60e39b7bffa54fbc990ac606030f5e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d2e3cdb42dd439b9133a542acc9cfda",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0777bd360f5b490ea4897643c1ccaef0",
            "value": 125
          }
        },
        "ff91dfe9c2134a469570320d9cefb51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df8998d8eaf4265bd064199f0029056",
            "placeholder": "​",
            "style": "IPY_MODEL_b530233a90494d47bd2c615f2fcc1c3c",
            "value": " 125/125 [00:00&lt;00:00, 7.66kB/s]"
          }
        },
        "cf50d97c409d45798650790c5b2ad9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e514881e37534da585e0f3a86936cd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca241f0c99e94627b12c0a4e4b072887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2e3cdb42dd439b9133a542acc9cfda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0777bd360f5b490ea4897643c1ccaef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2df8998d8eaf4265bd064199f0029056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b530233a90494d47bd2c615f2fcc1c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f51bb3e8cebf4a9f83174c7736344670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a562e5791b94cb39cf2f87967e7274e",
              "IPY_MODEL_4468e5b80fd44321a0ceb1c37f73d052",
              "IPY_MODEL_7bf4761c4a1d442d927b677f1347257f"
            ],
            "layout": "IPY_MODEL_c29958326c5e499cb23437cb2612d8a9"
          }
        },
        "4a562e5791b94cb39cf2f87967e7274e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869413a2c46b40b692fda2c13ede61f4",
            "placeholder": "​",
            "style": "IPY_MODEL_23ab09409aba4c34a35049b026d7aa80",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4468e5b80fd44321a0ceb1c37f73d052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b24b917d2849638690bce24c232ada",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60d62cfc078d4187b2cb6416c8bffa9e",
            "value": 366
          }
        },
        "7bf4761c4a1d442d927b677f1347257f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e666d765cb604a45aaf01cecdd771772",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f0cb6b6f684ac0b95ae6234f5d30d3",
            "value": " 366/366 [00:00&lt;00:00, 31.8kB/s]"
          }
        },
        "c29958326c5e499cb23437cb2612d8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869413a2c46b40b692fda2c13ede61f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ab09409aba4c34a35049b026d7aa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b24b917d2849638690bce24c232ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d62cfc078d4187b2cb6416c8bffa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e666d765cb604a45aaf01cecdd771772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f0cb6b6f684ac0b95ae6234f5d30d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}